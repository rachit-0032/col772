{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2018ME10032_A3_A_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSkHozvq7gGh"
      },
      "source": [
        "Make a copy of this notebook and rename using your USERID in the following format, 2017CSZ8058\n",
        "\n",
        "Give editor access to keshavkolluru@gmail.com, vishalsaley114@gmail.com and kartikeya.badola@gmail.com\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPmKrdbC48JU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "943d6e78-3d4b-423f-8293-83db2006ec7f"
      },
      "source": [
        "## DONT CHANGE THIS CELL \n",
        "# this is currently the same as dev.data.txt\n",
        "!wget http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.data.txt"
      ],
      "execution_count": 498,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-11 13:48:44--  http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.data.txt\n",
            "Resolving www.cse.iitd.ac.in (www.cse.iitd.ac.in)... 103.27.9.152\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.data.txt [following]\n",
            "--2021-10-11 13:48:44--  https://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.data.txt\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 63639 (62K) [text/plain]\n",
            "Saving to: ‘test.data.txt’\n",
            "\n",
            "test.data.txt       100%[===================>]  62.15K   171KB/s    in 0.4s    \n",
            "\n",
            "2021-10-11 13:48:45 (171 KB/s) - ‘test.data.txt’ saved [63639/63639]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJv-12oi_zKg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f1d31df-8d91-4f64-913e-4c0949ba205f"
      },
      "source": [
        "## Replace with the right link that contains the zip file uploaded from the training\n",
        "!gdown https://drive.google.com/uc?id=1nQsR62wLqfmw2_kZHjSSisB9R72FByML"
      ],
      "execution_count": 502,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nQsR62wLqfmw2_kZHjSSisB9R72FByML\n",
            "To: /content/2018ME10032_A_model.zip\n",
            "100% 29.1M/29.1M [00:00<00:00, 70.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPboluHagvSZ",
        "outputId": "157a173b-da42-4098-82da-7658416ea100"
      },
      "source": [
        "!unzip 2018ME10032_A_model.zip"
      ],
      "execution_count": 503,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  2018ME10032_A_model.zip\n",
            "replace model.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: model.txt               \n",
            "  inflating: vocab.txt               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLf89g6JhWoP"
      },
      "source": [
        "## Import relevant packages\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
        "from torchtext.vocab import GloVe"
      ],
      "execution_count": 505,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLBdU6SKoNIR"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(0)"
      ],
      "execution_count": 506,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA8k_AktsdTs",
        "outputId": "e50abf73-b15f-44e0-f5f2-686b8a832862"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 507,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJItiNqji7v7"
      },
      "source": [
        "vocab = torch.load('vocab.txt')"
      ],
      "execution_count": 508,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF6tNFAYPkUs"
      },
      "source": [
        ""
      ],
      "execution_count": 508,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7GB9WKvPkm9"
      },
      "source": [
        "## Creating .CSV Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMfEc5Hlnxm4"
      },
      "source": [
        "def csv_creator(path_data='/content/test.data.txt', path_dir='content/', is_label=False, kind='train'):\n",
        "    ## Reading Data File\n",
        "    train_list = []\n",
        "    count = 1\n",
        "    with open(path_data, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.rstrip('\\n')\n",
        "            line = line.split('\\t')\n",
        "            token = line[0]\n",
        "            entity = line[1]\n",
        "            pos = line[2].split('-')\n",
        "            pos1 = pos[0]\n",
        "            pos2 = pos[1]\n",
        "            sent1 = line[3]\n",
        "            ## Punctuation if removed shall change the current order of words \n",
        "            ## and thus the significance of the indices given shall be lost\n",
        "            sent1 = ' '.join(sent1.split())\n",
        "            sent2 = line[4]\n",
        "            sent2 = ' '.join(sent2.split())\n",
        "            train_list.append({\"Token\": token, \"Entity\": entity, \"Position1\": pos1, \n",
        "                              \"Position2\": pos2, \"Sentence1\": sent1, \"Sentence2\": sent2})\n",
        "        f.close()\n",
        "\n",
        "    ## Creating DataFrame for the data\n",
        "    train_df = pd.DataFrame(train_list)\n",
        "\n",
        "    ## Label Encoding\n",
        "    train_df['Entity'] = np.where(train_df['Entity'] == 'V', 1, 0)\n",
        "\n",
        "    # Reading Gold Labels\n",
        "    if is_label:\n",
        "        label_list = []\n",
        "        with open(path_gold, 'r') as f:\n",
        "            label_list = f.read().splitlines()\n",
        "            f.close()\n",
        "\n",
        "        ## Label Encoding\n",
        "        for i in range(len(label_list)):\n",
        "            if label_list[i] == 'T':\n",
        "                label_list[i] = 1\n",
        "            else:\n",
        "                label_list[i] = 0\n",
        "        train_df['Label'] = label_list\n",
        "    \n",
        "    path_csv = path_dir + str(kind) + '.csv'\n",
        "    train_df['Index'] = np.arange(0, len(train_df), 1)      ## Adding index to ensure no shuffling\n",
        "    train_df.to_csv(path_csv, index=True)"
      ],
      "execution_count": 509,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0n015efn_Lm"
      },
      "source": [
        "csv_creator(path_data='/content/test.data.txt', path_dir = '/content/', is_label=False, kind='test')"
      ],
      "execution_count": 510,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7ZMUb53oGbm"
      },
      "source": [
        ""
      ],
      "execution_count": 510,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkmIta9ZQCq9"
      },
      "source": [
        "## Creating Iteratable Format for Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l7HEIyuof_7"
      },
      "source": [
        "tokenizer = lambda x: x.split()"
      ],
      "execution_count": 511,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2stHJAOoof86"
      },
      "source": [
        "text_field = Field(sequential=True, use_vocab=True, tokenize=tokenizer, lower=True, batch_first=True, include_lengths=True)\n",
        "label_field = Field(sequential=False, use_vocab=False, batch_first=True)"
      ],
      "execution_count": 512,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DldejO1Jof6Y"
      },
      "source": [
        "fields = {'Token': ('t', text_field), 'Entity': ('e', label_field), 'Position1': ('p1', label_field), \n",
        "          'Position2': ('p2', label_field), 'Sentence1': ('s1', text_field), 'Sentence2': ('s2', text_field), 'Index': ('i', label_field)}"
      ],
      "execution_count": 513,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_AIH4szofzV"
      },
      "source": [
        "test_data = TabularDataset(\n",
        "    path = '/content/test.csv',\n",
        "    format = 'csv',\n",
        "    fields = fields,\n",
        ")"
      ],
      "execution_count": 514,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJbGQu7L3JxN"
      },
      "source": [
        "text_field.vocab = vocab"
      ],
      "execution_count": 515,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M42CoHZWzGXk",
        "outputId": "7b01d1dd-e983-426b-f84e-a5742d6f9361"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 516,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "638"
            ]
          },
          "metadata": {},
          "execution_count": 516
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXThb1GoolV3",
        "outputId": "8ab1ae90-b64f-4f99-b648-3dc5b0bd55c5"
      },
      "source": [
        "print(test_data[0].__dict__.keys())\n",
        "print(test_data[0].__dict__.values())"
      ],
      "execution_count": 517,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['t', 'e', 'p1', 'p2', 's1', 's2', 'i'])\n",
            "dict_values([['board'], '0', '2', '2', ['room', 'and', 'board', '.'], ['he', 'nailed', 'boards', 'across', 'the', 'windows', '.'], '0'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJmJMw5folTc"
      },
      "source": [
        "test_iterator = BucketIterator(\n",
        "    test_data,\n",
        "    batch_size=len(test_data),\n",
        "    sort_key=lambda x: len(list(x.i)),\n",
        "    device=device,\n",
        "    sort=True,\n",
        "    sort_within_batch=True\n",
        ")"
      ],
      "execution_count": 518,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjeTbO6foa4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "277b6115-cfd4-422d-be5c-452988b61cdf"
      },
      "source": [
        "count = 0\n",
        "for batch in test_iterator:\n",
        "    if count < 5:\n",
        "        print(batch.i)\n",
        "        count += 1"
      ],
      "execution_count": 519,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([637, 636, 635, 634, 633, 632, 631, 630, 629, 628, 627, 626, 625, 624,\n",
            "        623, 622, 621, 620, 619, 618, 617, 616, 615, 614, 613, 612, 611, 610,\n",
            "        609, 608, 607, 606, 605, 604, 603, 602, 601, 600, 599, 598, 597, 596,\n",
            "        595, 594, 593, 592, 591, 590, 589, 588, 587, 586, 585, 584, 583, 582,\n",
            "        581, 580, 579, 578, 577, 576, 575, 574, 573, 572, 571, 570, 569, 568,\n",
            "        567, 566, 565, 564, 563, 562, 561, 560, 559, 558, 557, 556, 555, 554,\n",
            "        553, 552, 551, 550, 549, 548, 547, 546, 545, 544, 543, 542, 541, 540,\n",
            "        539, 538, 537, 536, 535, 534, 533, 532, 531, 530, 529, 528, 527, 526,\n",
            "        525, 524, 523, 522, 521, 520, 519, 518, 517, 516, 515, 514, 513, 512,\n",
            "        511, 510, 509, 508, 507, 506, 505, 504, 503, 502, 501, 500, 499, 498,\n",
            "        497, 496, 495, 494, 493, 492, 491, 490, 489, 488, 487, 486, 485, 484,\n",
            "        483, 482, 481, 480, 479, 478, 477, 476, 475, 474, 473, 472, 471, 470,\n",
            "        469, 468, 467, 466, 465, 464, 463, 462, 461, 460, 459, 458, 457, 456,\n",
            "        455, 454, 453, 452, 451, 450, 449, 448, 447, 446, 445, 444, 443, 442,\n",
            "        441, 440, 439, 438, 437, 436, 435, 434, 433, 432, 431, 430, 429, 428,\n",
            "        427, 426, 425, 424, 423, 422, 421, 420, 419, 418, 417, 416, 415, 414,\n",
            "        413, 412, 411, 410, 409, 408, 407, 406, 405, 404, 403, 402, 401, 400,\n",
            "        399, 398, 397, 396, 395, 394, 393, 392, 391, 390, 389, 388, 387, 386,\n",
            "        385, 384, 383, 382, 381, 380, 379, 378, 377, 376, 375, 374, 373, 372,\n",
            "        371, 370, 369, 368, 367, 366, 365, 364, 363, 362, 361, 360, 359, 358,\n",
            "        357, 356, 355, 354, 353, 352, 351, 350, 349, 348, 347, 346, 345, 344,\n",
            "        343, 342, 341, 340, 339, 338, 337, 336, 335, 334, 333, 332, 331, 330,\n",
            "        329, 328, 327, 326, 325, 324, 323, 322, 321, 320, 319, 318, 317, 316,\n",
            "        315, 314, 313, 312, 311, 310, 309, 308, 307, 306, 305, 304, 303, 302,\n",
            "        301, 300, 299, 298, 297, 296, 295, 294, 293, 292, 291, 290, 289, 288,\n",
            "        287, 286, 285, 284, 283, 282, 281, 280, 279, 278, 277, 276, 275, 274,\n",
            "        273, 272, 271, 270, 269, 268, 267, 266, 265, 264, 263, 262, 261, 260,\n",
            "        259, 258, 257, 256, 255, 254, 253, 252, 251, 250, 249, 248, 247, 246,\n",
            "        245, 244, 243, 242, 241, 240, 239, 238, 237, 236, 235, 234, 233, 232,\n",
            "        231, 230, 229, 228, 227, 226, 225, 224, 223, 222, 221, 220, 219, 218,\n",
            "        217, 216, 215, 214, 213, 212, 211, 210, 209, 208, 207, 206, 205, 204,\n",
            "        203, 202, 201, 200, 199, 198, 197, 196, 195, 194, 193, 192, 191, 190,\n",
            "        189, 188, 187, 186, 185, 184, 183, 182, 181, 180, 179, 178, 177, 176,\n",
            "        175, 174, 173, 172, 171, 170, 169, 168, 167, 166, 165, 164, 163, 162,\n",
            "        161, 160, 159, 158, 157, 156, 155, 154, 153, 152, 151, 150, 149, 148,\n",
            "        147, 146, 145, 144, 143, 142, 141, 140, 139, 138, 137, 136, 135, 134,\n",
            "        133, 132, 131, 130, 129, 128, 127, 126, 125, 124, 123, 122, 121, 120,\n",
            "        119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106,\n",
            "        105, 104, 103, 102, 101, 100,  99,  98,  97,  96,  95,  94,  93,  92,\n",
            "         91,  90,  89,  88,  87,  86,  85,  84,  83,  82,  81,  80,  79,  78,\n",
            "         77,  76,  75,  74,  73,  72,  71,  70,  69,  68,  67,  66,  65,  64,\n",
            "         63,  62,  61,  60,  59,  58,  57,  56,  55,  54,  53,  52,  51,  50,\n",
            "         49,  48,  47,  46,  45,  44,  43,  42,  41,  40,  39,  38,  37,  36,\n",
            "         35,  34,  33,  32,  31,  30,  29,  28,  27,  26,  25,  24,  23,  22,\n",
            "         21,  20,  19,  18,  17,  16,  15,  14,  13,  12,  11,  10,   9,   8,\n",
            "          7,   6,   5,   4,   3,   2,   1,   0], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e300kiCzlHLp"
      },
      "source": [
        "class BiLSTM_WordMeaningComparison(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim,\n",
        "                 hidden, n_layers):\n",
        "        super(BiLSTM_WordMeaningComparison, self).__init__()    ## loading from parent class\n",
        "        self.hidden = hidden\n",
        "        self.n_layers = n_layers\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.embed.weight.data.copy_(text_field.vocab.vectors)\n",
        "        self.embed.weight.requires_grad = False     ## Freezing the embeddings\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden,\n",
        "                            num_layers=n_layers,\n",
        "                            bidirectional=True,     ## makes it a BiLSTM\n",
        "                            batch_first=True)\n",
        "        drp1 = 0.5      # dropout probability\n",
        "        self.dropout1 = nn.Dropout(drp1)\n",
        "        self.fc1 = nn.Linear(hidden * 2, 32)        ## fully connected layer\n",
        "\n",
        "    def forward(self, input, actual_batch_len):\n",
        "        embed_out = self.embed(input)\n",
        "        hidden = torch.zeros(self.n_layers * 2, input.shape[0], self.hidden, requires_grad=True).to(device)   ## hidden state\n",
        "        cell = torch.zeros( self.n_layers * 2, input.shape[0], self.hidden, requires_grad=True).to(device)    ## cell state\n",
        "        out_lstm, (hidden, cell) = self.lstm(embed_out,(hidden, cell)) # Applying BiLSTM Model\n",
        "        out_lstm = self.dropout1(out_lstm)                             # Applying dropout\n",
        "        out_lstm = self.fc1(out_lstm)                                  # Applying Fully connected layer\n",
        "        return out_lstm\n",
        "\n",
        "## Defining input parameters for the model\n",
        "vocab_dim = len(text_field.vocab)\n",
        "embedding_dim = text_field.vocab.vectors.shape[1]\n",
        "hidden_dim = 256\n",
        "num_layers = 1\n",
        "model = BiLSTM_WordMeaningComparison(vocab_dim, embedding_dim, hidden_dim, num_layers)"
      ],
      "execution_count": 520,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVbaMgZrlg-5",
        "outputId": "d73ceb62-0feb-4bbe-9909-cdc2e1d1a462"
      },
      "source": [
        "## Defining Optimizer and Criterion\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CosineEmbeddingLoss()          ## to gain a measure of similarity between the two word embeddings\n",
        "model.to(device)"
      ],
      "execution_count": 521,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM_WordMeaningComparison(\n",
              "  (embed): Embedding(7460, 300)\n",
              "  (lstm): LSTM(300, 256, batch_first=True, bidirectional=True)\n",
              "  (dropout1): Dropout(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 521
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YScoV3-gzzO",
        "outputId": "23132b0e-ae32-4af7-a82b-51d15b33527b"
      },
      "source": [
        "## Loading saved model\n",
        "checkpoint = torch.load('model.txt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "model.eval()"
      ],
      "execution_count": 522,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM_WordMeaningComparison(\n",
              "  (embed): Embedding(7460, 300)\n",
              "  (lstm): LSTM(300, 256, batch_first=True, bidirectional=True)\n",
              "  (dropout1): Dropout(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 522
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYBGHwnlniVs",
        "outputId": "087596fe-ad59-40a9-e430-d7975c58294a"
      },
      "source": [
        "print(\"model = \", model)\n",
        "print(\"optimizer = \", opt)\n",
        "print(\"epoch = \", epoch)\n",
        "print(\"loss = \", loss)"
      ],
      "execution_count": 523,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model =  BiLSTM_WordMeaningComparison(\n",
            "  (embed): Embedding(7460, 300)\n",
            "  (lstm): LSTM(300, 256, batch_first=True, bidirectional=True)\n",
            "  (dropout1): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
            ")\n",
            "optimizer =  Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            ")\n",
            "epoch =  12\n",
            "loss =  0.42919013623533575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq2BDhFYyuDZ",
        "outputId": "cad246b7-25e5-40c5-98b2-a4ddd7c2bb2f"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": 524,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM_WordMeaningComparison(\n",
              "  (embed): Embedding(7460, 300)\n",
              "  (lstm): LSTM(300, 256, batch_first=True, bidirectional=True)\n",
              "  (dropout1): Dropout(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 524
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb1j8Y0bs2hg"
      },
      "source": [
        "## Defining Accuracy\n",
        "def accuracy(preds, y):\n",
        "    acc = torch.sum(preds == y) / y.shape[0]\n",
        "    return acc\n",
        "\n",
        "## Calculating Loss\n",
        "def calculateLoss(model, batch, criterion):\n",
        "    ## Running BiLSTM for Sentence 1\n",
        "    text, text_len = batch.s1\n",
        "    p1 = batch.p1\n",
        "    embeddings = model(text, text_len.to(device))\n",
        "\n",
        "    ## Running BiLSTM for Sentence 2\n",
        "    text_2, text_len_2 = batch.s2\n",
        "    p2 = batch.p2\n",
        "    embeddings_2 = model(text_2, text_len_2.to(device))\n",
        "\n",
        "    ## Picking out the specific word embeddings from the output for sentence 1\n",
        "    j = 1\n",
        "    first = embeddings[0, p1[0], :]\n",
        "    for i in p1[1:]:\n",
        "        first = torch.vstack((first, embeddings[j, i, :]))\n",
        "        j += 1\n",
        "\n",
        "    ## Picking out the specific word embeddings from the output for sentence 2\n",
        "    j = 1\n",
        "    second = embeddings_2[0, p2[0], :]\n",
        "    for i in p2[1:]:\n",
        "        second = torch.vstack((second, embeddings_2[j, i, :]))\n",
        "        j += 1\n",
        "\n",
        "    ## Generating cosine similarity\n",
        "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "    res = cos(first, second).float()\n",
        "\n",
        "    for i in range(len(res)):\n",
        "        if res[i] > 0.645:\n",
        "          res[i] = 1\n",
        "        else:\n",
        "          res[i] = 0\n",
        "    \n",
        "    return res"
      ],
      "execution_count": 580,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sh-Mw6cAIcH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06ae035-090a-4649-9f56-1cdb8c509e70"
      },
      "source": [
        "## Generating results\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for batch in test_iterator:\n",
        "        if count == 0:\n",
        "            val_results = calculateLoss(model, batch, criterion)\n",
        "            count += 1\n",
        "        else:\n",
        "            val_results = torch.cat((val_results, calculateLoss(model, batch, criterion)), 0)\n",
        "    print(val_results)"
      ],
      "execution_count": 581,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
            "        1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
            "        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
            "        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
            "        1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
            "        0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
            "        0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
            "        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
            "        0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
            "        0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
            "        0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
            "        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
            "        1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
            "        1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
            "        1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
            "        0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
            "        1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
            "        1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
            "        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
            "        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
            "        1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
            "        0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
            "        0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
            "        1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
            "        1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
            "        0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
            "        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
            "        0., 1., 1., 1., 1., 1., 0., 1.], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKabKRthnMcK",
        "outputId": "47fea191-852e-45c4-9b00-eb72ff33fb3e"
      },
      "source": [
        "## Converting results to T and F format\n",
        "res = []\n",
        "for i in val_results:\n",
        "    if i.int() == 0:\n",
        "        res.append('F')\n",
        "    else:\n",
        "        res.append('T')\n",
        "res.reverse()\n",
        "print(len(res))\n",
        "print(res)"
      ],
      "execution_count": 582,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "638\n",
            "['T', 'F', 'T', 'T', 'T', 'T', 'T', 'F', 'T', 'F', 'F', 'F', 'F', 'T', 'F', 'F', 'T', 'F', 'T', 'T', 'T', 'T', 'F', 'F', 'T', 'F', 'T', 'T', 'T', 'T', 'T', 'T', 'F', 'F', 'T', 'F', 'T', 'F', 'F', 'T', 'T', 'T', 'F', 'F', 'F', 'T', 'F', 'T', 'F', 'T', 'F', 'F', 'T', 'F', 'F', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'F', 'T', 'T', 'T', 'T', 'T', 'F', 'F', 'F', 'F', 'F', 'F', 'T', 'F', 'T', 'F', 'T', 'T', 'T', 'T', 'F', 'F', 'F', 'F', 'F', 'F', 'T', 'F', 'T', 'F', 'T', 'T', 'T', 'F', 'T', 'T', 'T', 'F', 'F', 'T', 'T', 'T', 'F', 'F', 'F', 'T', 'T', 'T', 'F', 'T', 'F', 'F', 'F', 'T', 'T', 'F', 'T', 'T', 'F', 'T', 'T', 'F', 'F', 'T', 'T', 'T', 'T', 'F', 'F', 'T', 'F', 'F', 'F', 'F', 'F', 'T', 'T', 'T', 'T', 'F', 'F', 'T', 'T', 'T', 'T', 'F', 'T', 'F', 'F', 'F', 'T', 'T', 'F', 'F', 'F', 'F', 'F', 'T', 'T', 'F', 'T', 'F', 'F', 'T', 'F', 'T', 'T', 'F', 'T', 'T', 'T', 'T', 'T', 'F', 'T', 'T', 'T', 'T', 'F', 'T', 'F', 'T', 'T', 'F', 'F', 'T', 'F', 'F', 'T', 'T', 'F', 'F', 'F', 'T', 'T', 'T', 'T', 'F', 'T', 'T', 'F', 'F', 'T', 'F', 'T', 'T', 'T', 'F', 'T', 'F', 'F', 'F', 'T', 'T', 'T', 'F', 'F', 'F', 'F', 'T', 'F', 'F', 'T', 'F', 'F', 'T', 'F', 'T', 'F', 'T', 'T', 'F', 'F', 'F', 'T', 'F', 'T', 'T', 'F', 'F', 'F', 'T', 'F', 'F', 'F', 'F', 'T', 'F', 'T', 'F', 'F', 'F', 'F', 'F', 'F', 'T', 'T', 'T', 'F', 'T', 'T', 'F', 'T', 'F', 'T', 'F', 'F', 'F', 'F', 'F', 'T', 'F', 'T', 'F', 'T', 'T', 'F', 'F', 'T', 'T', 'F', 'T', 'F', 'T', 'T', 'T', 'T', 'F', 'F', 'F', 'F', 'T', 'F', 'T', 'T', 'T', 'F', 'F', 'F', 'T', 'F', 'T', 'F', 'T', 'T', 'F', 'T', 'F', 'T', 'F', 'T', 'F', 'T', 'F', 'T', 'F', 'T', 'T', 'F', 'T', 'F', 'T', 'T', 'F', 'F', 'F', 'F', 'F', 'F', 'T', 'F', 'T', 'T', 'F', 'T', 'T', 'F', 'T', 'F', 'F', 'F', 'T', 'F', 'T', 'F', 'T', 'F', 'F', 'F', 'T', 'F', 'F', 'F', 'T', 'F', 'T', 'F', 'F', 'F', 'F', 'F', 'F', 'T', 'F', 'T', 'T', 'T', 'F', 'T', 'F', 'T', 'F', 'F', 'T', 'F', 'F', 'T', 'F', 'T', 'F', 'T', 'F', 'F', 'F', 'F', 'F', 'F', 'T', 'F', 'F', 'F', 'T', 'T', 'F', 'F', 'T', 'F', 'T', 'F', 'F', 'T', 'T', 'F', 'F', 'T', 'F', 'F', 'T', 'F', 'T', 'T', 'T', 'T', 'T', 'T', 'F', 'T', 'T', 'F', 'T', 'T', 'F', 'T', 'T', 'F', 'T', 'T', 'F', 'T', 'F', 'T', 'F', 'F', 'F', 'F', 'T', 'F', 'T', 'F', 'T', 'F', 'T', 'F', 'T', 'F', 'T', 'F', 'F', 'T', 'F', 'T', 'T', 'T', 'F', 'F', 'F', 'T', 'F', 'F', 'F', 'T', 'F', 'T', 'F', 'T', 'T', 'T', 'F', 'T', 'F', 'F', 'T', 'F', 'T', 'F', 'F', 'T', 'F', 'F', 'F', 'T', 'F', 'F', 'T', 'T', 'F', 'T', 'F', 'F', 'T', 'F', 'T', 'F', 'T', 'F', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'F', 'T', 'F', 'T', 'T', 'T', 'F', 'T', 'F', 'T', 'T', 'F', 'T', 'T', 'F', 'T', 'F', 'T', 'F', 'F', 'F', 'F', 'T', 'T', 'F', 'T', 'T', 'F', 'T', 'F', 'F', 'F', 'T', 'F', 'T', 'F', 'F', 'F', 'F', 'F', 'T', 'T', 'F', 'T', 'T', 'F', 'T', 'T', 'F', 'T', 'T', 'F', 'T', 'F', 'T', 'T', 'F', 'F', 'F', 'F', 'T', 'T', 'T', 'F', 'T', 'F', 'F', 'T', 'F', 'T', 'F', 'F', 'T', 'T', 'F', 'F', 'F', 'T', 'T', 'F', 'T', 'T', 'F', 'T', 'F', 'F', 'F', 'F', 'T', 'T', 'T', 'F', 'T', 'T', 'T', 'T', 'T', 'F', 'T', 'F', 'T', 'F', 'T', 'F', 'T', 'F', 'T', 'F', 'T', 'T', 'T', 'F', 'T', 'F', 'T', 'T', 'F', 'T', 'F', 'F', 'T', 'F', 'T', 'T', 'F', 'T', 'F', 'T', 'F', 'F', 'T', 'T', 'F']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u45iHtu7v_7L"
      },
      "source": [
        "## Saving results in the given format\n",
        "with open('output.txt', 'w') as f:\n",
        "    for item in res:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 583,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-IlAUkv7s1C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b3aad4-f0d8-446b-a41d-019f89833c85"
      },
      "source": [
        "## DONT CHANGE THIS CELL\n",
        "# Your testing code must produce a file output.txt with predictions as T and F in each line\n",
        "\n",
        "## Final Evaluation \n",
        "# this is currently the same as dev.gold.txt\n",
        "!wget http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.gold.txt\n",
        "correct, total = 0., 0.\n",
        "for prediction, gold in zip(open('output.txt'), open('test.gold.txt')):\n",
        "  prediction, gold = prediction.strip(), gold.strip()\n",
        "  total += 1\n",
        "  if prediction == gold:\n",
        "    correct += 1\n",
        "\n",
        "## Report this as the final validation performance \n",
        "print('Performance = ', (correct/total))"
      ],
      "execution_count": 584,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-11 13:53:45--  http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.gold.txt\n",
            "Resolving www.cse.iitd.ac.in (www.cse.iitd.ac.in)... 103.27.9.152\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.gold.txt [following]\n",
            "--2021-10-11 13:53:46--  https://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.gold.txt\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1276 (1.2K) [text/plain]\n",
            "Saving to: ‘test.gold.txt.11’\n",
            "\n",
            "test.gold.txt.11    100%[===================>]   1.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-11 13:53:46 (61.2 MB/s) - ‘test.gold.txt.11’ saved [1276/1276]\n",
            "\n",
            "Performance =  0.6128526645768025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO2wjX_I7WS3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}